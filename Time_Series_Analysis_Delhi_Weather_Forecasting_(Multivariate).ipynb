{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzt7OPrRjBc3Ged1GwDeQ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfaoktvian/DelhiWeatherForecaster_Dicoding/blob/main/Time_Series_Analysis_Delhi_Weather_Forecasting_(Multivariate).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_C6Mn4mHXu3F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://drive.google.com/uc?id=1AZRfFoyekqSYpri5183RmJjciRGz_ood', sep=',',\n",
        "                     infer_datetime_format=True, index_col='datetime', header=0)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "e63nyGshX5Tc",
        "outputId": "e415cd62-ad43-4bb1-9cb4-807b814927df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3337606437.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df = pd.read_csv('https://drive.google.com/uc?id=1AZRfFoyekqSYpri5183RmJjciRGz_ood', sep=',',\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
              "datetime                                                                   \n",
              "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
              "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
              "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
              "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
              "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
              "\n",
              "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
              "datetime                                                                \n",
              "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
              "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
              "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
              "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
              "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
              "\n",
              "                     Sub_metering_3  \n",
              "datetime                             \n",
              "2006-12-16 17:24:00            17.0  \n",
              "2006-12-16 17:25:00            16.0  \n",
              "2006-12-16 17:26:00            17.0  \n",
              "2006-12-16 17:27:00            17.0  \n",
              "2006-12-16 17:28:00            17.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42bba571-99e7-4435-b353-afbee998409d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:24:00</th>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.84</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:25:00</th>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.63</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:26:00</th>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.29</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:27:00</th>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:28:00</th>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.68</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42bba571-99e7-4435-b353-afbee998409d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42bba571-99e7-4435-b353-afbee998409d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42bba571-99e7-4435-b353-afbee998409d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 86400,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 86400,\n        \"samples\": [\n          \"2007-01-15 20:48:00\",\n          \"2007-02-09 02:41:00\",\n          \"2006-12-20 23:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_active_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.335541718985237,\n        \"min\": 0.194,\n        \"max\": 9.272,\n        \"num_unique_values\": 3347,\n        \"samples\": [\n          5.406,\n          5.626,\n          3.904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_reactive_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11762146304314272,\n        \"min\": 0.0,\n        \"max\": 0.874,\n        \"num_unique_values\": 377,\n        \"samples\": [\n          0.656,\n          0.466,\n          0.632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Voltage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.498535931183649,\n        \"min\": 224.68,\n        \"max\": 251.7,\n        \"num_unique_values\": 2174,\n        \"samples\": [\n          238.73,\n          248.19,\n          237.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.62946293858816,\n        \"min\": 0.8,\n        \"max\": 40.4,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          37.4,\n          36.2,\n          13.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.682567482878629,\n        \"min\": 0.0,\n        \"max\": 77.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          0.0,\n          36.0,\n          14.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.567679475711084,\n        \"min\": 0.0,\n        \"max\": 78.0,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          37.0,\n          40.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.671909304059401,\n        \"min\": 0.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          17.0,\n          12.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "data = df.values\n",
        "data = normalize_series(data, data.min(axis=0), data.max(axis=0))"
      ],
      "metadata": {
        "id": "Kb4AkTBhX9VJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_FEATURES = len(df.columns)\n",
        "SPLIT_TIME = int(len(data) * 0.5)\n",
        "x_train = data[:SPLIT_TIME]\n",
        "x_valid = data[SPLIT_TIME:]\n"
      ],
      "metadata": {
        "id": "L912b-_IdKhs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "6CGvPfAjdPl8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "N_PAST = 24\n",
        "N_FUTURE = 24\n",
        "SHIFT = 1\n",
        "# Kode untuk membuat windowed datasets\n",
        "train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)"
      ],
      "metadata": {
        "id": "sOMpSTKzdP5g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(64, input_shape=(N_PAST, N_FEATURES)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(N_FEATURES)\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufsQM48WdwOE",
        "outputId": "be270698-1663-43ba-893b-7c944c8d2b06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if (logs.get('mae') < 0.055 and logs.get('val_mae') < 0.055):\n",
        "                self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "lTepKLVtdy6m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss='mae',\n",
        "                  optimizer= optimizer,\n",
        "                  metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "Uucr-qqVd0rD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_set,\n",
        "          validation_data=(valid_set),\n",
        "          epochs=100,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmg9QiG5d2pN",
        "outputId": "34e98784-8671-47e1-935f-947002bbcd54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "   1343/Unknown \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0789 - mae: 0.0789"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0788 - mae: 0.0788 - val_loss: 0.0587 - val_mae: 0.0587\n",
            "Epoch 2/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0578 - val_mae: 0.0578\n",
            "Epoch 3/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 39ms/step - loss: 0.0593 - mae: 0.0593 - val_loss: 0.0578 - val_mae: 0.0578\n",
            "Epoch 4/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0588 - mae: 0.0588 - val_loss: 0.0573 - val_mae: 0.0573\n",
            "Epoch 5/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0573 - val_mae: 0.0573\n",
            "Epoch 6/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0583 - mae: 0.0583 - val_loss: 0.0566 - val_mae: 0.0566\n",
            "Epoch 7/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0572 - val_mae: 0.0572\n",
            "Epoch 8/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 56ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0564 - val_mae: 0.0564\n",
            "Epoch 9/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0565 - val_mae: 0.0565\n",
            "Epoch 10/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0574 - val_mae: 0.0574\n",
            "Epoch 11/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0585 - val_mae: 0.0585\n",
            "Epoch 12/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0583 - val_mae: 0.0583\n",
            "Epoch 13/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 41ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0578 - val_mae: 0.0578\n",
            "Epoch 14/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0576 - val_mae: 0.0576\n",
            "Epoch 15/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0581 - val_mae: 0.0581\n",
            "Epoch 16/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0575 - val_mae: 0.0575\n",
            "Epoch 17/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0568 - val_mae: 0.0568\n",
            "Epoch 18/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.0564 - mae: 0.0564 - val_loss: 0.0579 - val_mae: 0.0579\n",
            "Epoch 19/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 56ms/step - loss: 0.0566 - mae: 0.0566 - val_loss: 0.0558 - val_mae: 0.0558\n",
            "Epoch 20/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0564 - mae: 0.0564 - val_loss: 0.0576 - val_mae: 0.0576\n",
            "Epoch 21/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0564 - mae: 0.0564 - val_loss: 0.0576 - val_mae: 0.0576\n",
            "Epoch 22/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.0564 - mae: 0.0564 - val_loss: 0.0576 - val_mae: 0.0576\n",
            "Epoch 23/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0552 - val_mae: 0.0552\n",
            "Epoch 24/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 49ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0574 - val_mae: 0.0574\n",
            "Epoch 25/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0548 - val_mae: 0.0548\n",
            "Epoch 26/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0551 - val_mae: 0.0551\n",
            "Epoch 27/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0553 - val_mae: 0.0553\n",
            "Epoch 28/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0554 - val_mae: 0.0554\n",
            "Epoch 29/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0557 - val_mae: 0.0557\n",
            "Epoch 30/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0556 - val_mae: 0.0556\n",
            "Epoch 31/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0553 - val_mae: 0.0553\n",
            "Epoch 32/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0555 - val_mae: 0.0555\n",
            "Epoch 33/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0555 - val_mae: 0.0555\n",
            "Epoch 34/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0551 - val_mae: 0.0551\n",
            "Epoch 35/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0550 - val_mae: 0.0550\n",
            "Epoch 36/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0551 - val_mae: 0.0551\n",
            "Epoch 37/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0556 - val_mae: 0.0556\n",
            "Epoch 38/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0558 - val_mae: 0.0558\n",
            "Epoch 39/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0561 - val_mae: 0.0561\n",
            "Epoch 40/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 44ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0551 - val_mae: 0.0551\n",
            "Epoch 41/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0565 - val_mae: 0.0565\n",
            "Epoch 42/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0560 - val_mae: 0.0560\n",
            "Epoch 43/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0549 - val_mae: 0.0549\n",
            "Epoch 44/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0555 - mae: 0.0555 - val_loss: 0.0551 - val_mae: 0.0551\n",
            "Epoch 45/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0549 - val_mae: 0.0549\n",
            "Epoch 46/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0549 - val_mae: 0.0549\n",
            "Epoch 47/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0549 - val_mae: 0.0549\n",
            "Epoch 48/100\n",
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0549 - val_mae: 0.0549\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b33b8e9e720>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = model.predict(train_set)\n",
        "train_pred[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p3oczfOd4qA",
        "outputId": "3ac7112e-6844-452c-d8f3-2da1b4137d05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.3487157 ,  0.23414701,  0.03068485,  0.34852824, -0.00902002,\n",
              "       -0.0022408 ,  0.8443355 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcktSq2AlGaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kxfx-g6IlGWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}